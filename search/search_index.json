{
    "docs": [
        {
            "location": "/", 
            "text": "", 
            "title": "Home"
        }, 
        {
            "location": "/general/cvmfs/", 
            "text": "CVMFS\n\n\nUChicago hosts the CVMFS origin server (osg-cvmfs.grid.uchicago.edu) for several\nexperiments and the OSG module system. This server is a CentOS7 VM with \nsingularity that can be used to build EL6 versions of software. The \nrepositories are associated with a respective user, e.g. \n\nspt.opensciencegrid.org\n has an \nspt\n user, that are typically accessible to \nthe relevant members of the experiments.  The VM is fairly large with 8 cores \nand 16 GB RAM. The \n/cvmfs\n directory is a separate disk that can be resized \nif need be.\n\n\nModules\n\n\nThe modules are hosted out of the \nconnect.opensciencegrid.org\n subrepo. They\nare setup using (spack)[https://spack.io/]. A good place to start understanding \nspack is the spack tutuorial available \n(here)[https://spack.readthedocs.io/en/latest/tutorial.html]. There is a \n(fork of spack in the OSG Connect GitHub)[https://github.com/OSGConnect/spack] \nwhich contains a few necessary changes and additional packages. The main change \nrequired for OSG is that CentOS instances are considered the same as RHEL or \nSL. This is an artifact from using the python \nplatform\n package.\n\n\nPath Structure\n\n\nThe structure for the software is as follows:\n\n\n\n\n/cvmfs/connect.opensciencegrid.org\n\n\n \nmodules\n - Main directory\n\n \nspack\n - Spack instances\n\n \npackages\n - Where individual packages are installed\n\n* \nmodulefiles\n - Where lmod files are located\n\n\n\n\nConfiguration\n\n\nThere are some important spack config files that may need adjusting over time, \nesp. when trying to reconfigure the module structure or adding new \nfeatures:\n\n\nSPACK_ROOT=/cvmfs/connect.opensciencegrid.org/modules/spack\n\n\n\n\n$HOME/.spack/linux/compilers.yaml\n\n\n\n\nThis defines the compilers that can be used by spack. We currently list two \ncompilers by default here: GCC 4.8.5 installed using spack and GCC 6.4.0 also\ninstalled using spack. We had to install GCC 4.8.5 (system compiler for EL7) \nbecause certain programs, e.g. R, require \nlibgfortran\n to be present to run. \nThis is not guaranteed on OSG since some nodes do not have any development \ntools installed. GCC 6.4.0 is needed for support for C++14. \n\n\n\n\n$SPACK_ROOT/etc/spack/config.yaml\n\n\n\n\nDefines global configuration parameters for spack. In our case this is just \n\nwhere\n the packages will installed (\ninstall_tree\n) and \nwhere\n the module\nfiles will be located (\nmodule_roots/lmod\n). For other options see \n(here)[https://spack.readthedocs.io/en/latest/config_yaml.html#config-yaml]\n\n\n\n\n$SPACK_ROOT/etc/spack/packages.yaml\n\n\n\n\nDefines the global or package specific settings for build variants. This means \nthat it allows one to turn on or off certain package-specific configuration \nparameters. In our case, we want to disable the need for packages to compile \nwith MPI support and reduce the number of versions of certain libraries, e.g. \nalways compile \nlibxml2\n with python support.\n\n\n\n\n$SPACK_ROOT/etc/spack/modules.yaml\n\n\n\n\nDefines the organization and general settings for creating module files. For \nexample, in our cause we have suffixes to differentiate versions that depend\non Python 2.7 and 3.7 and only the lmod modules are enabled.\n\n\nAdding a Module\n\n\nAdding a new module is fairly straight forward. On the CVMFS origin host, log \nin as the \nconnect\n user. Now start a CVMFS transaction:\n\n\ncvmfs_server transaction connect.opensciencegrid.org\n\n\n\n\n\nPlease note that only a single transaction can be open at a time, so if you \ndon't finish the transaction (for example building ROOT takes hours) no one \nelse can add new modules while a transaction is active. \n\n\nOnce the transaction has been started, go to the spack \nbin\n directory, \n\n$SPACK_ROOT/bin/\n:\n\n\ncd /cvmfs/connect.opensciencegrid.org/modules/spack/bin\n\n\nIf the desired piece of software and version is available in the (spack\npackage list)[https://spack.readthedocs.io/en/latest/package_list.html], simply \nrun\n\n\nspack install \npackage\n@\nversion\n%gcc@\ngcc_version\n\n\n\n\n\n\nTo check what \ngcc_version\ns are available see \n\n$HOME/.spack/linux/compilers.yaml\n\n\nAdding a new version of a piece of software requires editing the respective \npackage file using\n\n\nspack edit \npackage\n\n\n\n\n\n\nAdding a new package is fairly straightforward as well. Simply run\n\n\nspack create \nurl_to_package_tarball\n\n\n\n\n\n\nand edit the resulting file as needed, e.g. add dependencies, add \nconfigure/cmake options, etc. For examples check out various other packages in \n\n$SPACK_ROOT/var/spack/repos/builtin/packages/\n.\n\n\nExperiments\n\n\nSPT\n\n\nSee Midscale-Engagements\n\n\nXENON\n\n\nSee Midscale-Engagements\n\n\nVERITAS\n\n\nSee Midscale-Engagements\n\n\nnEXO\n\n\nThe nEXO repository is handled by OSG personnel. The organization is the same \nas the SPT repos. The repo is very much in flux because of the development of \nthe nEXO MonteCarlo software.\n\n\nDependency List\n\n\nShortened list\nBoost 1.67.0\ncmake 3.11.1\ngeant4 10.04.p01\npython 2.7.14\nROOT 6.12.06 with builtin_fftw3, using our gsl 1.16, minuit on, caster off, \nroofit on, rfio off, xrootd off, gfal and ruby disabled \nvgm 4.4  http://ivana.home.cern.ch", 
            "title": "CVMFS"
        }, 
        {
            "location": "/general/cvmfs/#cvmfs", 
            "text": "UChicago hosts the CVMFS origin server (osg-cvmfs.grid.uchicago.edu) for several\nexperiments and the OSG module system. This server is a CentOS7 VM with \nsingularity that can be used to build EL6 versions of software. The \nrepositories are associated with a respective user, e.g.  spt.opensciencegrid.org  has an  spt  user, that are typically accessible to \nthe relevant members of the experiments.  The VM is fairly large with 8 cores \nand 16 GB RAM. The  /cvmfs  directory is a separate disk that can be resized \nif need be.", 
            "title": "CVMFS"
        }, 
        {
            "location": "/general/cvmfs/#modules", 
            "text": "The modules are hosted out of the  connect.opensciencegrid.org  subrepo. They\nare setup using (spack)[https://spack.io/]. A good place to start understanding \nspack is the spack tutuorial available \n(here)[https://spack.readthedocs.io/en/latest/tutorial.html]. There is a \n(fork of spack in the OSG Connect GitHub)[https://github.com/OSGConnect/spack] \nwhich contains a few necessary changes and additional packages. The main change \nrequired for OSG is that CentOS instances are considered the same as RHEL or \nSL. This is an artifact from using the python  platform  package.", 
            "title": "Modules"
        }, 
        {
            "location": "/general/cvmfs/#path-structure", 
            "text": "The structure for the software is as follows:   /cvmfs/connect.opensciencegrid.org    modules  - Main directory   spack  - Spack instances   packages  - Where individual packages are installed *  modulefiles  - Where lmod files are located", 
            "title": "Path Structure"
        }, 
        {
            "location": "/general/cvmfs/#configuration", 
            "text": "There are some important spack config files that may need adjusting over time, \nesp. when trying to reconfigure the module structure or adding new \nfeatures:  SPACK_ROOT=/cvmfs/connect.opensciencegrid.org/modules/spack   $HOME/.spack/linux/compilers.yaml   This defines the compilers that can be used by spack. We currently list two \ncompilers by default here: GCC 4.8.5 installed using spack and GCC 6.4.0 also\ninstalled using spack. We had to install GCC 4.8.5 (system compiler for EL7) \nbecause certain programs, e.g. R, require  libgfortran  to be present to run. \nThis is not guaranteed on OSG since some nodes do not have any development \ntools installed. GCC 6.4.0 is needed for support for C++14.    $SPACK_ROOT/etc/spack/config.yaml   Defines global configuration parameters for spack. In our case this is just  where  the packages will installed ( install_tree ) and  where  the module\nfiles will be located ( module_roots/lmod ). For other options see \n(here)[https://spack.readthedocs.io/en/latest/config_yaml.html#config-yaml]   $SPACK_ROOT/etc/spack/packages.yaml   Defines the global or package specific settings for build variants. This means \nthat it allows one to turn on or off certain package-specific configuration \nparameters. In our case, we want to disable the need for packages to compile \nwith MPI support and reduce the number of versions of certain libraries, e.g. \nalways compile  libxml2  with python support.   $SPACK_ROOT/etc/spack/modules.yaml   Defines the organization and general settings for creating module files. For \nexample, in our cause we have suffixes to differentiate versions that depend\non Python 2.7 and 3.7 and only the lmod modules are enabled.", 
            "title": "Configuration"
        }, 
        {
            "location": "/general/cvmfs/#adding-a-module", 
            "text": "Adding a new module is fairly straight forward. On the CVMFS origin host, log \nin as the  connect  user. Now start a CVMFS transaction:  cvmfs_server transaction connect.opensciencegrid.org  Please note that only a single transaction can be open at a time, so if you \ndon't finish the transaction (for example building ROOT takes hours) no one \nelse can add new modules while a transaction is active.   Once the transaction has been started, go to the spack  bin  directory,  $SPACK_ROOT/bin/ :  cd /cvmfs/connect.opensciencegrid.org/modules/spack/bin  If the desired piece of software and version is available in the (spack\npackage list)[https://spack.readthedocs.io/en/latest/package_list.html], simply \nrun  spack install  package @ version %gcc@ gcc_version   To check what  gcc_version s are available see  $HOME/.spack/linux/compilers.yaml  Adding a new version of a piece of software requires editing the respective \npackage file using  spack edit  package   Adding a new package is fairly straightforward as well. Simply run  spack create  url_to_package_tarball   and edit the resulting file as needed, e.g. add dependencies, add \nconfigure/cmake options, etc. For examples check out various other packages in  $SPACK_ROOT/var/spack/repos/builtin/packages/ .", 
            "title": "Adding a Module"
        }, 
        {
            "location": "/general/cvmfs/#experiments", 
            "text": "", 
            "title": "Experiments"
        }, 
        {
            "location": "/general/cvmfs/#spt", 
            "text": "See Midscale-Engagements", 
            "title": "SPT"
        }, 
        {
            "location": "/general/cvmfs/#xenon", 
            "text": "See Midscale-Engagements", 
            "title": "XENON"
        }, 
        {
            "location": "/general/cvmfs/#veritas", 
            "text": "See Midscale-Engagements", 
            "title": "VERITAS"
        }, 
        {
            "location": "/general/cvmfs/#nexo", 
            "text": "The nEXO repository is handled by OSG personnel. The organization is the same \nas the SPT repos. The repo is very much in flux because of the development of \nthe nEXO MonteCarlo software.", 
            "title": "nEXO"
        }, 
        {
            "location": "/general/cvmfs/#dependency-list", 
            "text": "Shortened list\nBoost 1.67.0\ncmake 3.11.1\ngeant4 10.04.p01\npython 2.7.14\nROOT 6.12.06 with builtin_fftw3, using our gsl 1.16, minuit on, caster off, \nroofit on, rfio off, xrootd off, gfal and ruby disabled \nvgm 4.4  http://ivana.home.cern.ch", 
            "title": "Dependency List"
        }, 
        {
            "location": "/accounts-and-projects/general/", 
            "text": "OSG User Support Internal Documentation\n\n\nCreating Accounts in OSG Connect\n\n\nThe account creation workflow for OSG Connect follows a fairly straightforward \nworkflow:\n\n\n\n\nUsers enter through one of the Connect websites, e.g. www.osgconnect.net\n\n\nThe user creates a Globus ID\n\n\nUser applies for membership in the respective top-level connect project, \ne.g. \nosg\n for OSG Connect \nwith their Globus ID\n\n\nE-mail gets sent to \"Manager\"s and \"Admin\"s of the top-level connect project \nand a ticket gets created in FreshDesk\n\n\nA designated OSG user support staff member contacts the user\n\n\nThe designated OSG user support staff member approves the user adds the \nuser to the required project, e.g. osg.Biograph for members of Alex Feltus'\ngroup at Clemson\n\n\nIf there is no sub-project available, the user will have request a project\nto be created\n\n\nOnce every hour the user and project list is synced from Globus to a \njson\n\nfile on \nservice.ci-connect.net\n\n\nPuppet/heira will check the \njson\n file and creat missing users and groups \nas needed.\n\n\n\n\nUpdating Accounts in OSG Connect\n\n\nThe only updates that need to be made to a user account are:\n\n\n\n\nChange SSH key\n\n\n\n\nChanging the user SSH key needs to be performed by the user by going to\nhttps://portal.osgconnect.net/globus-app/account and add/remove the SSH key\nin the \"Manage SSH and X.509 keys\" window.\n\n\n\n\nChange project membership\n\n\n\n\nTo add a user to a project, either the user can request being added to the \nproject, or have a \"Manager\"/\"Admin\" invite the user to the project. If the \nuser is a member of the top-level project, e.g. \nosg\n, a \"Manager\"/\"Admin\" can \n\"invite\" the user and the user is added to the group automatically. If the user \nis not a member of the top-level project, the user can request membership in an \nproject or a a \"Manager\"/\"Admin\" can \"invite\" the user. If the user is invited, \nthe user will receive and email and have to accept the invitation. \n\n\n\n\nDelete user\n\n\n\n\nTo delete a user, the \"Manager\"/\"Admin\" can simply remove the user from the \nproject.\n\n\nIn all these cases, the synchronization step will propagate the changes from \nGlobus through the \njson\n file to puppet and ultimately the servers. \n\n\nKnown Issues\n\n\nUsername during Sign up procedure\n\n\nOne issue that appears in about 1/3 of user sign ups is that the user uses \na non-Globus ID to request membership in the respective top-level project. This \nis caused by the fact that the user link their institutional credentials to \ntheir Globus ID or never create a Globus ID. The former is much more frequent \nthan the latter. \n\n\nIf the user has a Globus ID, one can invite them to the group with that. The \nuser will receive an email that they need to accept. This step also allows one \nto check whether the user has a Globus ID.\n\n\nOSG Stash Globus Endpoint\n\n\nIf the user does not have the Globus ID as their primary ID, e.g. their \ninstitutional ID or their GMail, the setup of the Globus endpoint for OSG Stash \nwill not work. This has to do with using the Globus MyProxy server as the \nsource for authentication. Without having the Globus ID as the primary, this \nwill not work.", 
            "title": "General"
        }, 
        {
            "location": "/accounts-and-projects/general/#osg-user-support-internal-documentation", 
            "text": "", 
            "title": "OSG User Support Internal Documentation"
        }, 
        {
            "location": "/accounts-and-projects/general/#creating-accounts-in-osg-connect", 
            "text": "The account creation workflow for OSG Connect follows a fairly straightforward \nworkflow:   Users enter through one of the Connect websites, e.g. www.osgconnect.net  The user creates a Globus ID  User applies for membership in the respective top-level connect project, \ne.g.  osg  for OSG Connect  with their Globus ID  E-mail gets sent to \"Manager\"s and \"Admin\"s of the top-level connect project \nand a ticket gets created in FreshDesk  A designated OSG user support staff member contacts the user  The designated OSG user support staff member approves the user adds the \nuser to the required project, e.g. osg.Biograph for members of Alex Feltus'\ngroup at Clemson  If there is no sub-project available, the user will have request a project\nto be created  Once every hour the user and project list is synced from Globus to a  json \nfile on  service.ci-connect.net  Puppet/heira will check the  json  file and creat missing users and groups \nas needed.", 
            "title": "Creating Accounts in OSG Connect"
        }, 
        {
            "location": "/accounts-and-projects/general/#updating-accounts-in-osg-connect", 
            "text": "The only updates that need to be made to a user account are:   Change SSH key   Changing the user SSH key needs to be performed by the user by going to\nhttps://portal.osgconnect.net/globus-app/account and add/remove the SSH key\nin the \"Manage SSH and X.509 keys\" window.   Change project membership   To add a user to a project, either the user can request being added to the \nproject, or have a \"Manager\"/\"Admin\" invite the user to the project. If the \nuser is a member of the top-level project, e.g.  osg , a \"Manager\"/\"Admin\" can \n\"invite\" the user and the user is added to the group automatically. If the user \nis not a member of the top-level project, the user can request membership in an \nproject or a a \"Manager\"/\"Admin\" can \"invite\" the user. If the user is invited, \nthe user will receive and email and have to accept the invitation.    Delete user   To delete a user, the \"Manager\"/\"Admin\" can simply remove the user from the \nproject.  In all these cases, the synchronization step will propagate the changes from \nGlobus through the  json  file to puppet and ultimately the servers.", 
            "title": "Updating Accounts in OSG Connect"
        }, 
        {
            "location": "/accounts-and-projects/general/#known-issues", 
            "text": "", 
            "title": "Known Issues"
        }, 
        {
            "location": "/accounts-and-projects/general/#username-during-sign-up-procedure", 
            "text": "One issue that appears in about 1/3 of user sign ups is that the user uses \na non-Globus ID to request membership in the respective top-level project. This \nis caused by the fact that the user link their institutional credentials to \ntheir Globus ID or never create a Globus ID. The former is much more frequent \nthan the latter.   If the user has a Globus ID, one can invite them to the group with that. The \nuser will receive an email that they need to accept. This step also allows one \nto check whether the user has a Globus ID.", 
            "title": "Username during Sign up procedure"
        }, 
        {
            "location": "/accounts-and-projects/general/#osg-stash-globus-endpoint", 
            "text": "If the user does not have the Globus ID as their primary ID, e.g. their \ninstitutional ID or their GMail, the setup of the Globus endpoint for OSG Stash \nwill not work. This has to do with using the Globus MyProxy server as the \nsource for authentication. Without having the Globus ID as the primary, this \nwill not work.", 
            "title": "OSG Stash Globus Endpoint"
        }, 
        {
            "location": "/accounts-and-projects/accounts/", 
            "text": "Accounts\n\n\nRequirements for Users\n\n\nUsers need to satisfy the following in order to be approved:\n\n\n\n\nMust provide an institutional email address (e.g. user@university.edu, etc.)\n\n\nMust apply with using globusid account\n\n\nMust be affiliated with a US institution or research group\n\n\n\n\nProcess for Creating/Onboarding New OSG Connect Users\n\n\n\n\nReply to account request to schedule engagement meeting \n\n\nMeeting preparation\n\n\nMeet with the applicant\n\n\nComplete the onboarding process\n\n\n\n\nReply to Account Request to Schedule Engagement Meeting\n\n\nTicket changes\n\n\nCopy and paste the user's \"Member Info\" into a note in the account application ticket:\n\n\n\n\nGo to https://www.osgconnect.net and sign in.\n\n\nGo to Connect \n My Projects and click on the osg group.\n\n\nOn the \"About\" tab, select the name of the applicant and then click on \"Member Info\"\n\n\nCopy and paste the fields (Username, Full Name, E-mail Address, etc...) into the ticket as a note\n\n\n\n\nInitial Response\n\n\n\n\nDoes it look like they are a member of one of the special projects / Connect groups (Duke, Chicago, etc.) \n\n\nDo they have a Globus ID and a US institutional email?\n\n\nStandard response\n\n\nTBD\n\n\n\n\n\n\nIf no institutional email or Globus ID\n\n\nWe received your application to join OSG Connect.  The email you used for the account application is a XXXXX address.  Could you please re-apply and this time supply your XXXXX University email address so that we can verify your affiliation?  I will remove the current application so that you will be able to re-apply. \n\n\nWe got your application to join OSG Connect.  In the application, the username is XXXXXXX.  This username is based on an institute provided ID, but it needs to be a GlobusID.  On our system it is difficult to create and maintain a unix account with a username other than a globusID.  Could you please re-apply with a globusID as username as outlined here: https://osgconnect.net/signup.  I will remove your current pending application so that you will be able to re-apply.\n\n\n\n\n\n\nIf no apparent connection to US institution: \n\n\nWe received your application for an OSG Connect account. One of the requirements to have an account on OSG Connect is that the applicant needs to have an affiliation with  a US Institution.  Do you have an affiliation with a U.S. institution, organization, or project that was not listed on your application?\n\n\n\n\n\n\n\n\nNo response\n\n\n\n\nIf someone has not responded, send a follow-up email after one-week\n\n\nTBD\n\n\n\n\n\n\nIf they don't respond to the second email: \n\n\nReject request in OSG Connect\n\n\nChange ticket to \nresolved\n\n\n\n\n\n\n\n\nBefore the meeting\n\n\nGenerate the project: https://opensciencegrid.org/campus-research/accounts-and-projects/projects/ \n\n\nDuring meeting\n\n\nOnboarding discussion outline:\n\n\n\n\nTell me about your research in general\n\n\nHow does computing fit in\n\n\nShort term and Long term priorities\n\n\nWhat does computing look like (dimensions) for short term goals\n\n\nOne program run or many (how many)\n\n\nFor one program run - how long? How much memory? Input/output? Can the workflow be split? Software?\n\n\nIf the workflow isn\u2019t OSG friendly -\n refer to other computing resources\n\n\nAt this point describe HTC (vs HPC if they have previous familiarity) and then OSG\n\n\nHow OSG \u201caffects\u201d their software, file transfer and job submission\n\n\n\n\nAfter the meeting\n\n\nApprove to enter the osg group:\n\n\nDo the following to add user to the newly created project\n\n\n\n\nGo to https://www.osgconnect.net and login as the \nconnect\n user\n\n\nGo to Connect \n My Projects in the menu\n\n\nGo to osg group or relevant group if applying to another group\n\n\nClick on members and click on pencil icon next to user\n\n\nClick on Approve button\n\n\n\n\nAdd to their appropriate project:\n\n\nDo the following to add user to their project (new or already generated)\n\n\n\n\nGo to https://www.osgconnect.com and login as the \nconnect\n user\n\n\nGo to Connect \n My Projects in the menu\n\n\nScroll down to the appropriate project for the user\n\n\nClick on members, and then the \"Invite people to this group\" link\n\n\nSearch for user, and then hit the send invitation button\n\n\n\n\nSend follow-up email\n \n\n\nTBD\n\n\nTicket clean up\n\n\n\n\nPaste notes from onboarding meeting into ticket\n\n\nIf there are no outstanding issues, change the status of the ticket to \"resolved\" and the Type to \"on-boarding X weeks\".", 
            "title": "Accounts"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#accounts", 
            "text": "", 
            "title": "Accounts"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#requirements-for-users", 
            "text": "Users need to satisfy the following in order to be approved:   Must provide an institutional email address (e.g. user@university.edu, etc.)  Must apply with using globusid account  Must be affiliated with a US institution or research group", 
            "title": "Requirements for Users"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#process-for-creatingonboarding-new-osg-connect-users", 
            "text": "Reply to account request to schedule engagement meeting   Meeting preparation  Meet with the applicant  Complete the onboarding process", 
            "title": "Process for Creating/Onboarding New OSG Connect Users"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#reply-to-account-request-to-schedule-engagement-meeting", 
            "text": "Ticket changes  Copy and paste the user's \"Member Info\" into a note in the account application ticket:   Go to https://www.osgconnect.net and sign in.  Go to Connect   My Projects and click on the osg group.  On the \"About\" tab, select the name of the applicant and then click on \"Member Info\"  Copy and paste the fields (Username, Full Name, E-mail Address, etc...) into the ticket as a note   Initial Response   Does it look like they are a member of one of the special projects / Connect groups (Duke, Chicago, etc.)   Do they have a Globus ID and a US institutional email?  Standard response  TBD    If no institutional email or Globus ID  We received your application to join OSG Connect.  The email you used for the account application is a XXXXX address.  Could you please re-apply and this time supply your XXXXX University email address so that we can verify your affiliation?  I will remove the current application so that you will be able to re-apply.   We got your application to join OSG Connect.  In the application, the username is XXXXXXX.  This username is based on an institute provided ID, but it needs to be a GlobusID.  On our system it is difficult to create and maintain a unix account with a username other than a globusID.  Could you please re-apply with a globusID as username as outlined here: https://osgconnect.net/signup.  I will remove your current pending application so that you will be able to re-apply.    If no apparent connection to US institution:   We received your application for an OSG Connect account. One of the requirements to have an account on OSG Connect is that the applicant needs to have an affiliation with  a US Institution.  Do you have an affiliation with a U.S. institution, organization, or project that was not listed on your application?     No response   If someone has not responded, send a follow-up email after one-week  TBD    If they don't respond to the second email:   Reject request in OSG Connect  Change ticket to  resolved", 
            "title": "Reply to Account Request to Schedule Engagement Meeting"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#before-the-meeting", 
            "text": "Generate the project: https://opensciencegrid.org/campus-research/accounts-and-projects/projects/", 
            "title": "Before the meeting"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#during-meeting", 
            "text": "Onboarding discussion outline:   Tell me about your research in general  How does computing fit in  Short term and Long term priorities  What does computing look like (dimensions) for short term goals  One program run or many (how many)  For one program run - how long? How much memory? Input/output? Can the workflow be split? Software?  If the workflow isn\u2019t OSG friendly -  refer to other computing resources  At this point describe HTC (vs HPC if they have previous familiarity) and then OSG  How OSG \u201caffects\u201d their software, file transfer and job submission", 
            "title": "During meeting"
        }, 
        {
            "location": "/accounts-and-projects/accounts/#after-the-meeting", 
            "text": "Approve to enter the osg group:  Do the following to add user to the newly created project   Go to https://www.osgconnect.net and login as the  connect  user  Go to Connect   My Projects in the menu  Go to osg group or relevant group if applying to another group  Click on members and click on pencil icon next to user  Click on Approve button   Add to their appropriate project:  Do the following to add user to their project (new or already generated)   Go to https://www.osgconnect.com and login as the  connect  user  Go to Connect   My Projects in the menu  Scroll down to the appropriate project for the user  Click on members, and then the \"Invite people to this group\" link  Search for user, and then hit the send invitation button   Send follow-up email    TBD  Ticket clean up   Paste notes from onboarding meeting into ticket  If there are no outstanding issues, change the status of the ticket to \"resolved\" and the Type to \"on-boarding X weeks\".", 
            "title": "After the meeting"
        }, 
        {
            "location": "/accounts-and-projects/projects/", 
            "text": "Projects\n\n\nCreating a project in OSG Connect is fairly straightforward. The email received \nin Freshdesk entails the the information needed to create a group. Copy the \ninformation, e.g. \n\n\nYour Name: \nYour Email Address: \nProject Name: \nShort Project Name: \nField of Science: Evolutionary \nField of Science (if Other): \nPI Name: \nPI Email:\nPI Organization:\nPI Department:\nJoin Date: \nSponsor: \nOSG Sponsor Contact: \nProject Contact: \nProject Contact Email: \nTelephone Number: \nProject Description:\n\n\n\n\n\ninto a text file. This text file can then be past to \n./add_connect_group.py\n \nin \ngosync3\n. Do this on login03.osgconnect.net under \n/usr/local/gosync3/\n.\n\n\nUsing the the project information text file, the group can be added to the \nby running \n\n\n./add_connect_group.py --projectfile /path/to/file --parent \nparent_group\n\n\n\n\n\n\nAfter the project file has been created, log into Globus using \nconnect\n user and\nadd the required users to the project. Additionally, the project requestor or \nanother designated user needs to be made a \"Manager\" in Globus.\n\n\nThe project will also need to be added to the OSG topology at \n\n\nhttps://github.com/opensciencegrid/topology/tree/master/projects", 
            "title": "Projects"
        }, 
        {
            "location": "/accounts-and-projects/projects/#projects", 
            "text": "Creating a project in OSG Connect is fairly straightforward. The email received \nin Freshdesk entails the the information needed to create a group. Copy the \ninformation, e.g.   Your Name: \nYour Email Address: \nProject Name: \nShort Project Name: \nField of Science: Evolutionary \nField of Science (if Other): \nPI Name: \nPI Email:\nPI Organization:\nPI Department:\nJoin Date: \nSponsor: \nOSG Sponsor Contact: \nProject Contact: \nProject Contact Email: \nTelephone Number: \nProject Description:  into a text file. This text file can then be past to  ./add_connect_group.py  \nin  gosync3 . Do this on login03.osgconnect.net under  /usr/local/gosync3/ .  Using the the project information text file, the group can be added to the \nby running   ./add_connect_group.py --projectfile /path/to/file --parent  parent_group   After the project file has been created, log into Globus using  connect  user and\nadd the required users to the project. Additionally, the project requestor or \nanother designated user needs to be made a \"Manager\" in Globus.  The project will also need to be added to the OSG topology at   https://github.com/opensciencegrid/topology/tree/master/projects", 
            "title": "Projects"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/", 
            "text": "GOSync3\n\n\nGOSync3 is the replacement for the original GOSync. It is based on the \n\nGlobus SDK\n, the \n\nGlobus SDK-based Globus Nexus Client\n, \nand puppet/hiera to create and manage UNIX users and groups. The main tasks of \nthese classes and scripts are to interact with the GlobusID and Globus Groups \ndatabase through their RESTful API and manage the JSON file that \npuppet/hiera requires for creating and managing user accounts. \n\n\nThe original GOSync is based on the \n\nGlobus Nexus Python library\n. \nThe Globus Nexus Python library has been officially deprecated. An improved \nversion of the original GOSync, i.e. GOSync2, was under development. It was \nstill based on the Globus Nexus Python library. The development was abandoned \nas Globus has moved to a OAuth2-based authentication model and access to a \nuser's GlobusID.\n\n\nImportant notes READ BEFORE USING:\n\n\n\n\nThis is a BETA. It does not have all the necessary features to act as a full \nreplacement yet.\n\n\nThis version uses Globus Nexus client based on the Globus SDK created by \nStephen Rosen. This is not an official product of the Globus team. It is \nmaintained though.\n\n\n\n\nAssumptions\n\n\nFollowing assumptions are made in the code:\n\n\n\n\nAll users are part of the \nconnect\n Globus Group\n\n\nThe \nconnect\n user is an \nadmin\n or \nmanager\n in all relevant groups\n\n\n\n\nWork flow\n\n\nThe GOSync3 work flow is meant to operate without human intervention, i.e. as a \n\ncron\n job, besides the normal user approval process. At the moment, there is \nno connection between account applications and GOSync3. Hence, there is no way \nof knowing which user is new, updated his/her profile, or changed their group \nmembership. This should change in the future, see the last section for details.\n\n\nIn the current work flow, GOSync3 retrieves all groups in which the \nconnect\n \nuser is an \nAdministrator\n or \nManager\n. The \nconnect\n user acts like the root \nuser in a UNIX operating system. In addition to the group name and the UUID \nassigned by Globus Groups, the number of active members is being fetched by \nquerying the group's summary from Globus.  \n\n\nFor creating and updating users the work flow is more complicated. First, \nGOSync3 retrieves all users and their profile associated with the root group, \ni.e. \nconnect\n. It is necessary to fetch the user profile because it contains \nthe user's SSH key. To determine the the user's group membership, the the group \nto users mapping is generated by looping through all groups getting their group \nmembers. FRom this mapping a user to groups mapping is generated. With the \nnecessary information in hand, it the user information in the JSON object is \ncreated or updated.\n\n\nPrerequisites\n\n\nGOSync3 requires at least Python 2.7 and Python packages:\n\n\nglobus-sdk[jwt]\n=1.0,\n2.0\nglobus-nexus-client\n=0.2.5\n\n\n\n\n\nglobus-sdk[jwt]\n=1.0,\n2.0\n is the Globus SDK including the \n\nJSON Web Token (JWT)\n library. JWT is necessary to interact \nwith Globus Auth and be able to do token introspection. \n\nglobus-nexus-client\n=0.2.5\n is an implementation of the Nexus client using the \nGlobus SDK. It is not an official Globus product, but supported by one of the \nauthors (Stephen Rosen) of the Globus SDK.\n\n\nIn addition to the Python packages, one will need a Globus Confidential \napplication, see \nhere\n for \ndetails, that:\n\n\n\n\nIncludes the user-granted permissions (\"scopes\"):\n\n\nopenid\n\n\nprofile\n\n\nemail\n\n\nurn:globus:auth:scope:auth.globus.org:view_identity_set\n\n\nurn:globus:auth:scope:auth.globus.org:view_identities\n\n\nurn:globus:auth:scope:transfer.api.globus.org:all\n\n\nurn:globus:auth:scope:auth.globus.org:view_ssh_public_keys\n\n\n\n\n\n\nIs allowed to use the Group scopes. This requires filing a ticket with Globus \nto get the app ID added to the system\n\n\nHas the correct redirection URLs (this depends on the website you are running)\n\n\nRequires the GlobusID as an identity provider\n\n\nHas a secret associated with the application\n\n\n\n\nFor more details, please see the \n\nGlobus SDK documentation\n. \n\n\nConfiguration\n\n\nThe configuration is a JSON file for ease of parsing it as a dictionary. The \nminimal configuration needed is:\n\n\n{\n  \nusers\n: {\n    \npasswd_file\n: \npasswd_file_to_be_used\n\n    \ndefault_group\n: \ndefault_group for users\n\n  },\n  \ngroups\n: {\n    \ngroup_file\n: \ngroup_file_to_be_used\n\n  },\n  \nglobus\n: {\n    \ngroups\n: {\n      \nroot_group\n: \nroot_group\n,\n      \nroot_group_uuid\n: \nroot_group_globus_uuid\n\n    },\n    \nroot_user\n: {\n      // root user should only have admin or manager roles in the groups\n      \nroles\n: [\n        \nadmin\n,\n        \nmanager\n\n      ],\n      \nusername\n: \nroot_user\n,\n      \nsecret\n: \nroot_user_passwd\n,\n      \nauth_refresh_token\n: \nroot_user_globus_auth_token_for_app\n,\n      \nnexus_refresh_token\n: \nroot_user_globus_nexus_token_for_app\n\n    },\n    \nuser\n: {\n      // regular user may have any role in a group\n      \nroles\n: [\n        \nmember\n,\n        \nadmin\n,\n        \nmanager\n\n      ]\n    },\n    \napp\n: {\n      \nscopes\n: [\n        \nopenid\n,\n        \nprofile\n,\n        \nemail\n,\n        \nurn:globus:auth:scope:auth.globus.org:view_identities\n,\n        \nurn:globus:auth:scope:transfer.api.globus.org:all\n,\n        \nurn:globus:auth:scope:auth.globus.org:view_identity_set\n,\n        \nurn:globus:auth:scope:nexus.api.globus.org:groups\n\n      ],\n      \nclient_id\n: \nglobus_app_id_as_string\n,\n      \nclient_secret\n: \nglobus_app_secret_as_string\n\n    }\n  },\n  \nconnect_db\n: {\n    \ndb_file\n: \njson_file_to_be_used_as_connect_db\n\n  }\n}\n\n\n\n\n\nThis JSON object will be parsed into a Python dictionary and will be passed to \nthe various classes.\n\n\nExecute code\n\n\nSyncing User and Groups - \ngosync_globus_auth.py\n\n\nExecuting \ngosync_globus_auth.py\n will sync the users and groups from Globus. \nIf you want to run with you own config: \n\n./gosync_globus_auth.py --config /path/to/config\n. If you want to increase the \nverbosity, default the program will not print out anything to screen, simply \nadd the \n-v\n flag. To increase the verbosity, just add more \nv\ns, i.e. \n-vvvv\n.\n\n\nAdding Group - \nadd_connect_group.py\n\n\nTo add a group to Globus Groups requires, a file formatted as provided by the \nOSG Connect Website, details below. With the groups project file, a group is \nadded through executing \n\n./add_connect_group.py --projectfile /path/to/file --parent \nparent_group\n. \nThe \n--parent \nparent_group\n is optional, but necessary to maintain the group \ntree structure and determine the correct group name in Globus. To pass your own \nconfiguration you will need to the \n--config /path/to/new/config\n option. There \nis also a verbosity flag, i.e. \n-v\n, \n-vv\n, and \n-vvv\n. \n\n\nGlobus Interface - \nglobus_db.py\n\n\nThe class \nglobus_db\n is meant as an interface to the Globus ID and Globus \nGroups services. Please note that being able to \nPUT\n and \nPUSH\n information \ninto Globus Groups is possible through the Nexus interface. Currently, only \nthe \nPUT\n for Globus Groups is supported.\n\n\nThe class requires a configuration dictionary and an \nconnect_db\n object. The \nconfiguration dictionary is explained above. The \nconnect_db\n is needed to \nretrieve the the refresh tokens for users and allow of to check for changes \nin group membership, i.e. if users were added or removed from a group.\n\n\nThe class is split into four sections: client methods, group methods, group \nmembership methods, and user methods.\n\n\nClient Methods and some explanation about various Globus tokens\n\n\nThe client methods are for getting the different types of clients needed to \ninteract with GlobusID through Globus Auth and Globus Groups through Globus \nNexus. There are two main clients used: Globus Auth client and Globus Nexus \nclient. The Globus Auth client is for interacting with the user's GlobusID, i.e \nget the user profile in GlobusID. The Globus Nexus client is for interacting \nwith a user's Globus Groups and their Globus Groups's profile.\n\n\nThe clients can be authenticated using Globus Auth tokens or Globus Online Auth \nlegacy tokens. Tokens can be thought of as randomly generated passwords that \nencode the user's identity and the application's permission level. Globus \nOnline Auth legacy tokens will be referred to as legacy tokens from here on \nout. Legacy tokens should be avoided at all cost. They may not work down the \nroad and are bad practice.\n\n\nGlobus Auth tokens are OAuth2 tokens. OAuth2 gives the user and the \nauthorization server the explicit power to reject or limit (either in time or \nscope) an application's access, to the user's information. It also moves large \nparts of the authentication process from the resource provider to an \nauthentication provider, which allows for better separation between resources \nand authentication. For more details please visit \n\nAn introduction to OAuth2\n. \n\n\nThe Globus Auth tokens are split into three different types: Auth, Transfer, \nand Nexus. One will receive one, two, or all three, when a user authenticates \nagainst the app depending on an app's scopes, i.e. requested permissions. With \nthe app created in the prerequisites one will receive all three tokens. Auth \ntokens are meant for retrieving a user's information from Globus ID, i.e. \nlinked identities, SSH keys, etc. Transfer tokens are for initiating Globus \ntransfers on behalf of the user. Nexus tokens are for authorizing against the \nGlobus Groups service to allow viewing a user's group membership. The Nexus \ntokens do not allow to view a user's Globus groups profile through a call to \nthe user's Globus Nexus profile, i.e. the group-specific custom fields and the \nuser identity, directly. This due to the Nexus group scope not having the \npermissions to view the user's GlobusID. This can be circumvented by through \naccessing the profile through the groups interface instead. I know... Please \nnote that Nexus tokens are special. They are not officially available, one \nhas to request access to the \"group\" scopes from Globus. \n\n\nGlobus Auth tokens expire after some time, usually within 10 minutes, i.e. you \nas the application only have a limited amount of time to retrieve the desired \ninformation out of Globus. To be able to repeatedly authenticate with Globus \nAuth, one can request \"refresh tokens\". These tokens are valid until the user \nrevokes an app's permission. These are required for GOSync3.\n\n\nThe individual methods are self-explanatory:\n\n\n\n\nget_tokens\n: Returns a user's tokens from the \nconnect_db\n or retrieves \nthe tokens from the configuration file for the root user.\n\n\nget_legacy_client\n: Returns a user's Nexus client that has been \nauthenticated using legacy Globus Online Auth token, i.e. the \nuser's username/password.\n\n\nget_globus_client\n: Returns the user's Globus Auth and Globus Nexus client \nauthenticated using the user's refresh tokens. \n\n\n\n\nGroup Methods\n\n\nRetrieving Group Infomation - \nGET\n Methods\n\n\nThere are two ways to access all groups associated with \nconnect\n. The first is \nto the retrieve the group tree for the root group, named \nconnect\n. The second \nis to retrieve all groups associated with the root user, also named \nconnect\n. \n\n\nIn GOSyn3, we are using the second method. There is a method to retrieve the \ngroup tree, but it is unused at the moment. The \nget_group\n and \nget_groups\n \nmethod simply filter the \nall_groups\n list for the desired group(s). \n\nget_all_groups\n is the method that uses the root user's credentials to \ndetermine groups in which the root user, \nconnect\n, is an \nadmin\n or \nmanager\n. \nThe distinction between between being \nadmin\n, \nmanager\n, or \nmember\n is \nimportant here. It filters the groups that are returned by Globus Nexus. The \n\nconnect\n user will always be an \nadmin\n or \nmanager\n in a subgroup, while a \nuser might be a \nadmin\n, \nmanager\n, or \nmember\n. The root user is a \nmember\n \nof some groups that are not associated with the Connect instances. \n\n\nIn addition there is a \ncheck_new_members\n methods at is currently used. It \nallows to filter the group list to those groups that have recently added members. \n\n\nAdding Group Information - \nPOST\n Methods\n\n\nGOSync3 has the ability to add groups to Globus Groups. This is done through \nthe \nadd_group\n and \nparse_project_file\n methods. Adding a group is done \nthrough the \nadd_groups\n method. It calls the \nglobus-nexus-client\n's \n\ncreate_group\n method to create the group with name and description provided \nthrough the project description text file, details on this below. Optionally, \none can pass a parent group to the method. It is strongly recommended to \nprovide a parent group, without a group the group will be assumed to be a \ntop-level group below the root \nconnect\n group. \n\n\nThe project description text file should follow the format of the form on the \n\nNew Project section on the OSG Connect website\n. \nThis will provide a text file of the following format:\n\n\nYour Name: \nYour Email Address: \nProject Name: \nShort Project Name: \nField of Science: Evolutionary \nField of Science (if Other): \nPI Name: \nPI Email:\nPI Organization:\nPI Department:\nJoin Date: \nSponsor: \nOSG Sponsor Contact: \nProject Contact: \nProject Contact Email: \nTelephone Number: \nProject Description:\n\n\n\n\n\nFrom this the only required field is the \"Short Project Name\". The value will \nbe used as the group name in Globus Groups. \n\n\nparse_project_file\n parses the project file, determines the expected name of \nthe group, and converts the plain text to HTML-formatted text. The project name \nis determined from the \"Short Project Name\" in the project file and the parent \ngroup. The format of the Globus Groups name is \n\nparent_group\n.\nshort_project_name\n. To make the text HTML-formatted, the \nonly action is to converted newline characters (\n\\n\n) to \nbr\n.\n\n\nGroup Membership Methods\n\n\nThe work flow for retrieving a user's group membership depends on the \nauthentication method used. In a purely Globus Auth-based workflow, one would \nretrieve a user's group membership by using their tokens and calling \n\nlist_groups\n method from the Nexus client. This is done in the function \n\nget_user_groups_auth\n.\n\n\nAt the moment, we only have tokens for the \nconnect\n user. To work around this, \nGOSync3 tries to generate a mapping of group to users first and then inverts \nthat mapping, see function \nget_user_groups_no_tokens\n. It retrieves the list \nof all groups associated with the \nconnect\n user and then determines the group \nmembers for every group. Using \n_invert_dict_list_values\n, the group-to-users \nmapping is then inverted to the user-to-groups mapping. \n\n\nget_group_members\n simply returns the users for a given group. This has to be \ndone using the group's Globus UUID. A mapping of Globus group name to Globus \ngroup UUID is provided by the \nconnect_db\n.\n\n\nUser Methods\n\n\nThe user methods allow the user to retrieve more information about user, i.e. \nquery Globus for the user's \"user information\" and manipulate the Globus output \nin a more easily digestible patterns. \n\n\nget_user_info\n is a specialization of \nget_user_groups_profile\n. It allows to \nfetch the a user's profile, i.e. username, SSH key, group-specific information, \nfull name, e-mail, through Globus Groups. \nget_user_info\n is specialization in \nthe sense that it uses the root group user profile rather than specific group's \nprofile as needed by \nget_user_groups_profile\n.\n\n\nget_all_users\n retrieves all the users in the root group and then queries \nGlobus Groups for the user's profile. \n_invert_dict_list_values\n allows you \nto invert the group to users mapping to a user to groups mapping.\n\n\nPuppet/Hiera Interface - \nconnect_db.py\n\n\nIn this case, the JSON file used by puppet/hiera is used as a user database. \nThis is suboptimal. It will allow us to quickly deploy GOSync3. The information \nsource for the puppet/hiera JSON file can be replaced by a real DB later on. \nSome of the information, i.e. UNIX ids, stored in the JSON file will be needed \nto populate a replacement database.\n\n\nThe puppet/hiera interface, i.e \nconnect_db\n, is a thin layer of the JSON \nobject that puppet/hiera uses to provision user accounts. It reads a previous \nversion of the JSON object, and produces a \nusers\n and \ngroups\n dictionary and \na \nuids\n and \ngids\n list. These four objects contain all the necessary \ninformation to be able add new groups and users to the JSON object passed \nto puppet/hiera.\n\n\nThe \nusers\n and \ngroups\n dictionaries are made up of sub-dictionaries. Holding \nthe information for each user and group, respectively. The \nusers\n dictionary \nis a mapping of username to user information, such that:\n\n\n{\n    \nauth_refresh_token\n: # user\ns Globus Auth refresh token\n    \ncomment\n: # user\ns name\n    \nemail\n: # user\ns emails\n    \ngid\n: # default group for passwd file\n    \nmanage_group\n: # puppet/hiera config parameter\n    \nnexus_refresh_token\n: # user\ns Globus Nexus refresh token\n    \nshell\n: # default user shell\n    \nssh_keys\n: # SSH key dictionary, explained below\n    \nuid\n: # user\ns UNIX id\n    \ngroups\n: # list of user\ns groups,\n    \nconnect_project\n:  # Initial connect project, typically osg.ConnectTrain\n    \ncondor_schedd\n: # The condor schedd to pick on the login host\n}\n\n\n\n\n\nThe \ngroups\n dictionary follows a similar pattern. Mapping a group name to:\n\n\n{\n    \ngid\n: # group UNIX ID\n    \nnum_members\n: # Number if active user according to Globus\n    \nglobus_uuid\n: # Groups Globus UUID\n}\n\n\n\n\n\nSome of the methods in this class are self-explanatory:\n\n\n\n\nadd_group\n: Add a new group to the \ngroups\n dictionary\n\n\nadd_user\n: Add a new user to the \nusers\n dictionary\n\n\nget_user\n: Retrieve the user information by username\n\n\nget_group\n: Retrieve the group by group name\n\n\nnew_unix_id\n: This will generate a new UNIX id by incrementing the maximum \nID or setting it to 100000 for both groups and users\n\n\nget_member_count\n: Retrieve the group's active member count\n\n\nget_auth_token\n: Retrieve user's Globus Auth refresh token\n\n\nget_nexus_token\n: Retrieve user's Globus Nexus refresh token\n\n\nget_globus_tokens\n: Retrieves user's Globus Auth and Nexus refresh tokens\n\n\nremove_unicode\n: Remove unicode characters from a user's name. This can \ncause problems when generating a passwd file or trying to serialize a JSON file.\n\n\ncommit_old_version\n: In the spirit of old GOSync, we commit the JSON file to \nGitlab, so puppet/hiera can grab it from there\n\n\nwrite_db\n: Write the JSON object out. If \nemail_file\n is supplied in the \nconfig, it will also create a directory with json files that maps the group \nusers to their email addresses. Similarly, if \nmailchimp_file\n is supplied, \nit will also create a directory with json files that maps the group users to \ntheir information needed for mailchimp. \n\n\nset_user_nologin\n: Set a user's shell to nologin, used in case they are no \nlonger \"active\" in a Globus group\n\n\nget_emails\n: Get email for everyone or optionally for a given group\n\n\nget_email\n: Get email for a specific user\n\n\nget_mailchimp_info\n: Gather information about users for mailchimp. Mapping \nusers to their, first name, last name, and email address.\n\n\n\n\nThe \nget_default_project\n method is tries to guess a user's first OSG project \nfor account reasons. If the user is a member of more than more than one \nsub-project we need to filter out any of the default ones. First, \n\"osg.ConnectTrain\" is removed. If there are still more than one projects, we \nfilter out any project associated with a user school and any OSG project, if the\n user is a member of the other connect instances, i.e. SPT, ATLAS, CMS, and Duke. \n\n\nThe \ndecompose_sshkey\n method is necessary because of the format that \npuppet/hiera wants the SSH key in. A typical SSH key is formatted as follows:\n\n\nencryption_type\n \npublic_key\n \nidenitifier\n\n\n\n\n\n\nwhere the \nencryption_type\n is the type of SSH key, i.e. ssh-rsa, \n\npublic_key\n is the actual key portion of an SSH key, and \nidenitifier\n is \nan optional identifier that is usually \nusername\n@\nnetwork_hostname\n of the \nmachine the key pair was generated on. \n\n\nPuppet/hiera wants the key in this JSON object:\n\n\n{\n    \nidentifier\n:\n    {\n        \ntype\n: \nencryption_type\n # Encryption type, i.e. ssh-rsa, ssh-dsa\n        \nkey\n: \npublic_key\n # Key part\n    }\n}\n\n\n\n\n\nThis requires to split the key according to the spaces it in. Unfortunately, \nnot all keys have the identifier. In those cases it is replaced with the user's \nemail address. This will not affect operations. There is a question though \nabout overriding SSH keys. \n\n\nFuture Plans\n\n\nWork flow Improvements\n\n\nThere are three slow processes in the current work flow:\n\n\n\n\nGetting the group summary \n\n\nGetting the user summary\n\n\nGetting the user group memberships\n\n\n\n\nThe first processes are slow because we have to query the Globus Groups \ndatabase separately each piece of the group information: group profile, number \nof members, and group members, respectively. In addition, queries on the Globus \nside slow down as the group tree grows in size and as we add more groups the \nmore queries we have to perform. Getting the user summary is a similarly \nexpensive process because we have to query Globus for every user twice, once \nto get their general information, and another to get their SSH key.\n\n\nOne of the main steps to improve the efficiency requires to change the website \nto use OAuth2. This would allow us to operate on a per-user basis rather than \non a per-group basis. In an idealized work flow, a user would sign up on the \nwebsite. This sign up process would trigger the ability to retrieve the users \nidentity (including their SSH key)and their Globus OAuth tokens, see below for \nmore details on Globus OAuth tokens. With the identity and Globus token in \nhand, we can then query Globus for just the new user's group memberships. The \nfirst query would happen be default at sign up, while the group membership \nquery would come after they are approved. The second query may have to be \nrepeated several time. This is not wasted effort though, since we are waiting \nfor human intervention. Similarly, we could trigger a Globus query of a given \nuser's profile once they login. This would make updating the user information \non our end dependent on user actions rather than us having to repeatedly query \nGlobus for their information. Given that we most likely will never have tokens \nfor all users, we will need operate in a hybrid mode, where the new user's are \nhandled solely through the tokens, while older users will have still have to \nbe kept up to date through the above described work flow. \n\n\nPUT\n and \nPUSH\n Methods for Globus Interface\n\n\nTo create groups in Globus Groups, we will need to implement \nPUSH\n methods. \nThe \nNexusClient\n already has these, but they are untested. I will need to \ntest them before I can sanction them. I also want to standardize all \ninformation that is stored in Globus Groups for all the groups. Currently there \nare several different formats. \n\n\nMoving connect DB to a real DB\n\n\nThe data volume is not that large and the JSON file is sufficient to store all \nthe information. Down the road, we might want split from Globus and at this \npoint we need to retrieve all the data from Globus. Storing this data would \nneed a database.\n\n\nMultiple Connect Globus Apps\n\n\nBranded websites in Globus are mapped one-to-one to a specific Globus App. To \nhave different branded website for the various connect instances, we would need \nmultiple Globus Apps. Tokens are app-specific, so for users that are members of \nmultiple connect instances, for example CI Connect and OSG Connect, we will \nneed to keep track of different refresh tokens and apps that they are \nassociated with.", 
            "title": "GoSync3"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#gosync3", 
            "text": "GOSync3 is the replacement for the original GOSync. It is based on the  Globus SDK , the  Globus SDK-based Globus Nexus Client , \nand puppet/hiera to create and manage UNIX users and groups. The main tasks of \nthese classes and scripts are to interact with the GlobusID and Globus Groups \ndatabase through their RESTful API and manage the JSON file that \npuppet/hiera requires for creating and managing user accounts.   The original GOSync is based on the  Globus Nexus Python library . \nThe Globus Nexus Python library has been officially deprecated. An improved \nversion of the original GOSync, i.e. GOSync2, was under development. It was \nstill based on the Globus Nexus Python library. The development was abandoned \nas Globus has moved to a OAuth2-based authentication model and access to a \nuser's GlobusID.  Important notes READ BEFORE USING:   This is a BETA. It does not have all the necessary features to act as a full \nreplacement yet.  This version uses Globus Nexus client based on the Globus SDK created by \nStephen Rosen. This is not an official product of the Globus team. It is \nmaintained though.", 
            "title": "GOSync3"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#assumptions", 
            "text": "Following assumptions are made in the code:   All users are part of the  connect  Globus Group  The  connect  user is an  admin  or  manager  in all relevant groups", 
            "title": "Assumptions"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#work-flow", 
            "text": "The GOSync3 work flow is meant to operate without human intervention, i.e. as a  cron  job, besides the normal user approval process. At the moment, there is \nno connection between account applications and GOSync3. Hence, there is no way \nof knowing which user is new, updated his/her profile, or changed their group \nmembership. This should change in the future, see the last section for details.  In the current work flow, GOSync3 retrieves all groups in which the  connect  \nuser is an  Administrator  or  Manager . The  connect  user acts like the root \nuser in a UNIX operating system. In addition to the group name and the UUID \nassigned by Globus Groups, the number of active members is being fetched by \nquerying the group's summary from Globus.    For creating and updating users the work flow is more complicated. First, \nGOSync3 retrieves all users and their profile associated with the root group, \ni.e.  connect . It is necessary to fetch the user profile because it contains \nthe user's SSH key. To determine the the user's group membership, the the group \nto users mapping is generated by looping through all groups getting their group \nmembers. FRom this mapping a user to groups mapping is generated. With the \nnecessary information in hand, it the user information in the JSON object is \ncreated or updated.", 
            "title": "Work flow"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#prerequisites", 
            "text": "GOSync3 requires at least Python 2.7 and Python packages:  globus-sdk[jwt] =1.0, 2.0\nglobus-nexus-client =0.2.5  globus-sdk[jwt] =1.0, 2.0  is the Globus SDK including the  JSON Web Token (JWT)  library. JWT is necessary to interact \nwith Globus Auth and be able to do token introspection.  globus-nexus-client =0.2.5  is an implementation of the Nexus client using the \nGlobus SDK. It is not an official Globus product, but supported by one of the \nauthors (Stephen Rosen) of the Globus SDK.  In addition to the Python packages, one will need a Globus Confidential \napplication, see  here  for \ndetails, that:   Includes the user-granted permissions (\"scopes\"):  openid  profile  email  urn:globus:auth:scope:auth.globus.org:view_identity_set  urn:globus:auth:scope:auth.globus.org:view_identities  urn:globus:auth:scope:transfer.api.globus.org:all  urn:globus:auth:scope:auth.globus.org:view_ssh_public_keys    Is allowed to use the Group scopes. This requires filing a ticket with Globus \nto get the app ID added to the system  Has the correct redirection URLs (this depends on the website you are running)  Requires the GlobusID as an identity provider  Has a secret associated with the application   For more details, please see the  Globus SDK documentation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#configuration", 
            "text": "The configuration is a JSON file for ease of parsing it as a dictionary. The \nminimal configuration needed is:  {\n   users : {\n     passwd_file :  passwd_file_to_be_used \n     default_group :  default_group for users \n  },\n   groups : {\n     group_file :  group_file_to_be_used \n  },\n   globus : {\n     groups : {\n       root_group :  root_group ,\n       root_group_uuid :  root_group_globus_uuid \n    },\n     root_user : {\n      // root user should only have admin or manager roles in the groups\n       roles : [\n         admin ,\n         manager \n      ],\n       username :  root_user ,\n       secret :  root_user_passwd ,\n       auth_refresh_token :  root_user_globus_auth_token_for_app ,\n       nexus_refresh_token :  root_user_globus_nexus_token_for_app \n    },\n     user : {\n      // regular user may have any role in a group\n       roles : [\n         member ,\n         admin ,\n         manager \n      ]\n    },\n     app : {\n       scopes : [\n         openid ,\n         profile ,\n         email ,\n         urn:globus:auth:scope:auth.globus.org:view_identities ,\n         urn:globus:auth:scope:transfer.api.globus.org:all ,\n         urn:globus:auth:scope:auth.globus.org:view_identity_set ,\n         urn:globus:auth:scope:nexus.api.globus.org:groups \n      ],\n       client_id :  globus_app_id_as_string ,\n       client_secret :  globus_app_secret_as_string \n    }\n  },\n   connect_db : {\n     db_file :  json_file_to_be_used_as_connect_db \n  }\n}  This JSON object will be parsed into a Python dictionary and will be passed to \nthe various classes.", 
            "title": "Configuration"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#execute-code", 
            "text": "", 
            "title": "Execute code"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#syncing-user-and-groups-gosync_globus_authpy", 
            "text": "Executing  gosync_globus_auth.py  will sync the users and groups from Globus. \nIf you want to run with you own config:  ./gosync_globus_auth.py --config /path/to/config . If you want to increase the \nverbosity, default the program will not print out anything to screen, simply \nadd the  -v  flag. To increase the verbosity, just add more  v s, i.e.  -vvvv .", 
            "title": "Syncing User and Groups - gosync_globus_auth.py"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#adding-group-add_connect_grouppy", 
            "text": "To add a group to Globus Groups requires, a file formatted as provided by the \nOSG Connect Website, details below. With the groups project file, a group is \nadded through executing  ./add_connect_group.py --projectfile /path/to/file --parent  parent_group . \nThe  --parent  parent_group  is optional, but necessary to maintain the group \ntree structure and determine the correct group name in Globus. To pass your own \nconfiguration you will need to the  --config /path/to/new/config  option. There \nis also a verbosity flag, i.e.  -v ,  -vv , and  -vvv .", 
            "title": "Adding Group - add_connect_group.py"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#globus-interface-globus_dbpy", 
            "text": "The class  globus_db  is meant as an interface to the Globus ID and Globus \nGroups services. Please note that being able to  PUT  and  PUSH  information \ninto Globus Groups is possible through the Nexus interface. Currently, only \nthe  PUT  for Globus Groups is supported.  The class requires a configuration dictionary and an  connect_db  object. The \nconfiguration dictionary is explained above. The  connect_db  is needed to \nretrieve the the refresh tokens for users and allow of to check for changes \nin group membership, i.e. if users were added or removed from a group.  The class is split into four sections: client methods, group methods, group \nmembership methods, and user methods.", 
            "title": "Globus Interface - globus_db.py"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#client-methods-and-some-explanation-about-various-globus-tokens", 
            "text": "The client methods are for getting the different types of clients needed to \ninteract with GlobusID through Globus Auth and Globus Groups through Globus \nNexus. There are two main clients used: Globus Auth client and Globus Nexus \nclient. The Globus Auth client is for interacting with the user's GlobusID, i.e \nget the user profile in GlobusID. The Globus Nexus client is for interacting \nwith a user's Globus Groups and their Globus Groups's profile.  The clients can be authenticated using Globus Auth tokens or Globus Online Auth \nlegacy tokens. Tokens can be thought of as randomly generated passwords that \nencode the user's identity and the application's permission level. Globus \nOnline Auth legacy tokens will be referred to as legacy tokens from here on \nout. Legacy tokens should be avoided at all cost. They may not work down the \nroad and are bad practice.  Globus Auth tokens are OAuth2 tokens. OAuth2 gives the user and the \nauthorization server the explicit power to reject or limit (either in time or \nscope) an application's access, to the user's information. It also moves large \nparts of the authentication process from the resource provider to an \nauthentication provider, which allows for better separation between resources \nand authentication. For more details please visit  An introduction to OAuth2 .   The Globus Auth tokens are split into three different types: Auth, Transfer, \nand Nexus. One will receive one, two, or all three, when a user authenticates \nagainst the app depending on an app's scopes, i.e. requested permissions. With \nthe app created in the prerequisites one will receive all three tokens. Auth \ntokens are meant for retrieving a user's information from Globus ID, i.e. \nlinked identities, SSH keys, etc. Transfer tokens are for initiating Globus \ntransfers on behalf of the user. Nexus tokens are for authorizing against the \nGlobus Groups service to allow viewing a user's group membership. The Nexus \ntokens do not allow to view a user's Globus groups profile through a call to \nthe user's Globus Nexus profile, i.e. the group-specific custom fields and the \nuser identity, directly. This due to the Nexus group scope not having the \npermissions to view the user's GlobusID. This can be circumvented by through \naccessing the profile through the groups interface instead. I know... Please \nnote that Nexus tokens are special. They are not officially available, one \nhas to request access to the \"group\" scopes from Globus.   Globus Auth tokens expire after some time, usually within 10 minutes, i.e. you \nas the application only have a limited amount of time to retrieve the desired \ninformation out of Globus. To be able to repeatedly authenticate with Globus \nAuth, one can request \"refresh tokens\". These tokens are valid until the user \nrevokes an app's permission. These are required for GOSync3.  The individual methods are self-explanatory:   get_tokens : Returns a user's tokens from the  connect_db  or retrieves \nthe tokens from the configuration file for the root user.  get_legacy_client : Returns a user's Nexus client that has been \nauthenticated using legacy Globus Online Auth token, i.e. the \nuser's username/password.  get_globus_client : Returns the user's Globus Auth and Globus Nexus client \nauthenticated using the user's refresh tokens.", 
            "title": "Client Methods and some explanation about various Globus tokens"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#group-methods", 
            "text": "", 
            "title": "Group Methods"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#retrieving-group-infomation-get-methods", 
            "text": "There are two ways to access all groups associated with  connect . The first is \nto the retrieve the group tree for the root group, named  connect . The second \nis to retrieve all groups associated with the root user, also named  connect .   In GOSyn3, we are using the second method. There is a method to retrieve the \ngroup tree, but it is unused at the moment. The  get_group  and  get_groups  \nmethod simply filter the  all_groups  list for the desired group(s).  get_all_groups  is the method that uses the root user's credentials to \ndetermine groups in which the root user,  connect , is an  admin  or  manager . \nThe distinction between between being  admin ,  manager , or  member  is \nimportant here. It filters the groups that are returned by Globus Nexus. The  connect  user will always be an  admin  or  manager  in a subgroup, while a \nuser might be a  admin ,  manager , or  member . The root user is a  member  \nof some groups that are not associated with the Connect instances.   In addition there is a  check_new_members  methods at is currently used. It \nallows to filter the group list to those groups that have recently added members.", 
            "title": "Retrieving Group Infomation - GET Methods"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#adding-group-information-post-methods", 
            "text": "GOSync3 has the ability to add groups to Globus Groups. This is done through \nthe  add_group  and  parse_project_file  methods. Adding a group is done \nthrough the  add_groups  method. It calls the  globus-nexus-client 's  create_group  method to create the group with name and description provided \nthrough the project description text file, details on this below. Optionally, \none can pass a parent group to the method. It is strongly recommended to \nprovide a parent group, without a group the group will be assumed to be a \ntop-level group below the root  connect  group.   The project description text file should follow the format of the form on the  New Project section on the OSG Connect website . \nThis will provide a text file of the following format:  Your Name: \nYour Email Address: \nProject Name: \nShort Project Name: \nField of Science: Evolutionary \nField of Science (if Other): \nPI Name: \nPI Email:\nPI Organization:\nPI Department:\nJoin Date: \nSponsor: \nOSG Sponsor Contact: \nProject Contact: \nProject Contact Email: \nTelephone Number: \nProject Description:  From this the only required field is the \"Short Project Name\". The value will \nbe used as the group name in Globus Groups.   parse_project_file  parses the project file, determines the expected name of \nthe group, and converts the plain text to HTML-formatted text. The project name \nis determined from the \"Short Project Name\" in the project file and the parent \ngroup. The format of the Globus Groups name is  parent_group . short_project_name . To make the text HTML-formatted, the \nonly action is to converted newline characters ( \\n ) to  br .", 
            "title": "Adding Group Information - POST Methods"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#group-membership-methods", 
            "text": "The work flow for retrieving a user's group membership depends on the \nauthentication method used. In a purely Globus Auth-based workflow, one would \nretrieve a user's group membership by using their tokens and calling  list_groups  method from the Nexus client. This is done in the function  get_user_groups_auth .  At the moment, we only have tokens for the  connect  user. To work around this, \nGOSync3 tries to generate a mapping of group to users first and then inverts \nthat mapping, see function  get_user_groups_no_tokens . It retrieves the list \nof all groups associated with the  connect  user and then determines the group \nmembers for every group. Using  _invert_dict_list_values , the group-to-users \nmapping is then inverted to the user-to-groups mapping.   get_group_members  simply returns the users for a given group. This has to be \ndone using the group's Globus UUID. A mapping of Globus group name to Globus \ngroup UUID is provided by the  connect_db .", 
            "title": "Group Membership Methods"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#user-methods", 
            "text": "The user methods allow the user to retrieve more information about user, i.e. \nquery Globus for the user's \"user information\" and manipulate the Globus output \nin a more easily digestible patterns.   get_user_info  is a specialization of  get_user_groups_profile . It allows to \nfetch the a user's profile, i.e. username, SSH key, group-specific information, \nfull name, e-mail, through Globus Groups.  get_user_info  is specialization in \nthe sense that it uses the root group user profile rather than specific group's \nprofile as needed by  get_user_groups_profile .  get_all_users  retrieves all the users in the root group and then queries \nGlobus Groups for the user's profile.  _invert_dict_list_values  allows you \nto invert the group to users mapping to a user to groups mapping.", 
            "title": "User Methods"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#puppethiera-interface-connect_dbpy", 
            "text": "In this case, the JSON file used by puppet/hiera is used as a user database. \nThis is suboptimal. It will allow us to quickly deploy GOSync3. The information \nsource for the puppet/hiera JSON file can be replaced by a real DB later on. \nSome of the information, i.e. UNIX ids, stored in the JSON file will be needed \nto populate a replacement database.  The puppet/hiera interface, i.e  connect_db , is a thin layer of the JSON \nobject that puppet/hiera uses to provision user accounts. It reads a previous \nversion of the JSON object, and produces a  users  and  groups  dictionary and \na  uids  and  gids  list. These four objects contain all the necessary \ninformation to be able add new groups and users to the JSON object passed \nto puppet/hiera.  The  users  and  groups  dictionaries are made up of sub-dictionaries. Holding \nthe information for each user and group, respectively. The  users  dictionary \nis a mapping of username to user information, such that:  {\n     auth_refresh_token : # user s Globus Auth refresh token\n     comment : # user s name\n     email : # user s emails\n     gid : # default group for passwd file\n     manage_group : # puppet/hiera config parameter\n     nexus_refresh_token : # user s Globus Nexus refresh token\n     shell : # default user shell\n     ssh_keys : # SSH key dictionary, explained below\n     uid : # user s UNIX id\n     groups : # list of user s groups,\n     connect_project :  # Initial connect project, typically osg.ConnectTrain\n     condor_schedd : # The condor schedd to pick on the login host\n}  The  groups  dictionary follows a similar pattern. Mapping a group name to:  {\n     gid : # group UNIX ID\n     num_members : # Number if active user according to Globus\n     globus_uuid : # Groups Globus UUID\n}  Some of the methods in this class are self-explanatory:   add_group : Add a new group to the  groups  dictionary  add_user : Add a new user to the  users  dictionary  get_user : Retrieve the user information by username  get_group : Retrieve the group by group name  new_unix_id : This will generate a new UNIX id by incrementing the maximum \nID or setting it to 100000 for both groups and users  get_member_count : Retrieve the group's active member count  get_auth_token : Retrieve user's Globus Auth refresh token  get_nexus_token : Retrieve user's Globus Nexus refresh token  get_globus_tokens : Retrieves user's Globus Auth and Nexus refresh tokens  remove_unicode : Remove unicode characters from a user's name. This can \ncause problems when generating a passwd file or trying to serialize a JSON file.  commit_old_version : In the spirit of old GOSync, we commit the JSON file to \nGitlab, so puppet/hiera can grab it from there  write_db : Write the JSON object out. If  email_file  is supplied in the \nconfig, it will also create a directory with json files that maps the group \nusers to their email addresses. Similarly, if  mailchimp_file  is supplied, \nit will also create a directory with json files that maps the group users to \ntheir information needed for mailchimp.   set_user_nologin : Set a user's shell to nologin, used in case they are no \nlonger \"active\" in a Globus group  get_emails : Get email for everyone or optionally for a given group  get_email : Get email for a specific user  get_mailchimp_info : Gather information about users for mailchimp. Mapping \nusers to their, first name, last name, and email address.   The  get_default_project  method is tries to guess a user's first OSG project \nfor account reasons. If the user is a member of more than more than one \nsub-project we need to filter out any of the default ones. First, \n\"osg.ConnectTrain\" is removed. If there are still more than one projects, we \nfilter out any project associated with a user school and any OSG project, if the\n user is a member of the other connect instances, i.e. SPT, ATLAS, CMS, and Duke.   The  decompose_sshkey  method is necessary because of the format that \npuppet/hiera wants the SSH key in. A typical SSH key is formatted as follows:  encryption_type   public_key   idenitifier   where the  encryption_type  is the type of SSH key, i.e. ssh-rsa,  public_key  is the actual key portion of an SSH key, and  idenitifier  is \nan optional identifier that is usually  username @ network_hostname  of the \nmachine the key pair was generated on.   Puppet/hiera wants the key in this JSON object:  {\n     identifier :\n    {\n         type :  encryption_type  # Encryption type, i.e. ssh-rsa, ssh-dsa\n         key :  public_key  # Key part\n    }\n}  This requires to split the key according to the spaces it in. Unfortunately, \nnot all keys have the identifier. In those cases it is replaced with the user's \nemail address. This will not affect operations. There is a question though \nabout overriding SSH keys.", 
            "title": "Puppet/Hiera Interface - connect_db.py"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#future-plans", 
            "text": "", 
            "title": "Future Plans"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#work-flow-improvements", 
            "text": "There are three slow processes in the current work flow:   Getting the group summary   Getting the user summary  Getting the user group memberships   The first processes are slow because we have to query the Globus Groups \ndatabase separately each piece of the group information: group profile, number \nof members, and group members, respectively. In addition, queries on the Globus \nside slow down as the group tree grows in size and as we add more groups the \nmore queries we have to perform. Getting the user summary is a similarly \nexpensive process because we have to query Globus for every user twice, once \nto get their general information, and another to get their SSH key.  One of the main steps to improve the efficiency requires to change the website \nto use OAuth2. This would allow us to operate on a per-user basis rather than \non a per-group basis. In an idealized work flow, a user would sign up on the \nwebsite. This sign up process would trigger the ability to retrieve the users \nidentity (including their SSH key)and their Globus OAuth tokens, see below for \nmore details on Globus OAuth tokens. With the identity and Globus token in \nhand, we can then query Globus for just the new user's group memberships. The \nfirst query would happen be default at sign up, while the group membership \nquery would come after they are approved. The second query may have to be \nrepeated several time. This is not wasted effort though, since we are waiting \nfor human intervention. Similarly, we could trigger a Globus query of a given \nuser's profile once they login. This would make updating the user information \non our end dependent on user actions rather than us having to repeatedly query \nGlobus for their information. Given that we most likely will never have tokens \nfor all users, we will need operate in a hybrid mode, where the new user's are \nhandled solely through the tokens, while older users will have still have to \nbe kept up to date through the above described work flow.", 
            "title": "Work flow Improvements"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#put-and-push-methods-for-globus-interface", 
            "text": "To create groups in Globus Groups, we will need to implement  PUSH  methods. \nThe  NexusClient  already has these, but they are untested. I will need to \ntest them before I can sanction them. I also want to standardize all \ninformation that is stored in Globus Groups for all the groups. Currently there \nare several different formats.", 
            "title": "PUT and PUSH Methods for Globus Interface"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#moving-connect-db-to-a-real-db", 
            "text": "The data volume is not that large and the JSON file is sufficient to store all \nthe information. Down the road, we might want split from Globus and at this \npoint we need to retrieve all the data from Globus. Storing this data would \nneed a database.", 
            "title": "Moving connect DB to a real DB"
        }, 
        {
            "location": "/accounts-and-projects/gosync3/#multiple-connect-globus-apps", 
            "text": "Branded websites in Globus are mapped one-to-one to a specific Globus App. To \nhave different branded website for the various connect instances, we would need \nmultiple Globus Apps. Tokens are app-specific, so for users that are members of \nmultiple connect instances, for example CI Connect and OSG Connect, we will \nneed to keep track of different refresh tokens and apps that they are \nassociated with.", 
            "title": "Multiple Connect Globus Apps"
        }, 
        {
            "location": "/midscale-engagements/spt/general/", 
            "text": "South Pole Telescope\n\n\nSPT-3G, the third generation camera on the South Pole Telescope (SPT), was \ndeployed in the 2016-2017 Austral summer season. The SPT is a 10-meter \ntelescope located at the geographic South Pole and designed for observations in \nthe millimeter-wave and submillimeter-wave regions of the electromagnetic \nspectrum. The SPT is primarily used to study the cosmic microwave background \n(CMB). \n\n\nRequirements\n\n\nThe upgraded camera produces an order of magnitude more data than the \nprevious generations of SPT cameras. The telescope is expected to collect a \npetabyte (PB) of data over course of five years, which is a significantly \nlarger data volume than any other CMB telescope in operation. The increase \nin data rate required radical changes to the SPT computing model both at the \nSouth Pole and University of Chicago. This paper will describe the overall \nintegration of distributed storage and compute resources into a common \ninterface, deployment of on-site data reduction and storage infrastructure, \nand the usage of the Open Science Grid (OSG) by the SPT collaboration.\n\n\nData requirements:\n\n\n\n\n~ 150-200 TB of compressed raw data coming north every year in big boxes of \nhard drives \n\n\n~30 TB/year of reduced-rate data arriving continuously by satellite.\n\n\n\n\nComputing Requirements:\n\n\n\n\n~ 150 cores with 4 GB\n\n\n~ 10M core hours\n\n\n\n\nResources\n\n\nSPT has two dedicated login nodes. These are used for user analysis and job \nsubmission to OSG. To facilitate user analysis, there are Jupyterhub instances \nrunning on each of the login nodes. \n\n\nIn addition to the login nodes, there are two dedicated production resources: \n\nspt-buffer\n and \nspt-mgmt\n. \nspt-buffer\n is dedicated virtual machine that is \nrequired to retrieve the data via satellite from pole. United States Antarctic \nProgram (USAP)  \n\n\nNERSC Backups\n\n\nThere is automated", 
            "title": "General"
        }, 
        {
            "location": "/midscale-engagements/spt/general/#south-pole-telescope", 
            "text": "SPT-3G, the third generation camera on the South Pole Telescope (SPT), was \ndeployed in the 2016-2017 Austral summer season. The SPT is a 10-meter \ntelescope located at the geographic South Pole and designed for observations in \nthe millimeter-wave and submillimeter-wave regions of the electromagnetic \nspectrum. The SPT is primarily used to study the cosmic microwave background \n(CMB).", 
            "title": "South Pole Telescope"
        }, 
        {
            "location": "/midscale-engagements/spt/general/#requirements", 
            "text": "The upgraded camera produces an order of magnitude more data than the \nprevious generations of SPT cameras. The telescope is expected to collect a \npetabyte (PB) of data over course of five years, which is a significantly \nlarger data volume than any other CMB telescope in operation. The increase \nin data rate required radical changes to the SPT computing model both at the \nSouth Pole and University of Chicago. This paper will describe the overall \nintegration of distributed storage and compute resources into a common \ninterface, deployment of on-site data reduction and storage infrastructure, \nand the usage of the Open Science Grid (OSG) by the SPT collaboration.  Data requirements:   ~ 150-200 TB of compressed raw data coming north every year in big boxes of \nhard drives   ~30 TB/year of reduced-rate data arriving continuously by satellite.   Computing Requirements:   ~ 150 cores with 4 GB  ~ 10M core hours", 
            "title": "Requirements"
        }, 
        {
            "location": "/midscale-engagements/spt/general/#resources", 
            "text": "SPT has two dedicated login nodes. These are used for user analysis and job \nsubmission to OSG. To facilitate user analysis, there are Jupyterhub instances \nrunning on each of the login nodes.   In addition to the login nodes, there are two dedicated production resources:  spt-buffer  and  spt-mgmt .  spt-buffer  is dedicated virtual machine that is \nrequired to retrieve the data via satellite from pole. United States Antarctic \nProgram (USAP)", 
            "title": "Resources"
        }, 
        {
            "location": "/midscale-engagements/spt/general/#nersc-backups", 
            "text": "There is automated", 
            "title": "NERSC Backups"
        }, 
        {
            "location": "/midscale-engagements/spt/cvmfs/", 
            "text": "CVMFS\n\n\nThe SPT repo is handled by the experiment. The point of contact is Nathan\nWhitehorn. The structure follows a fairly simple pattern: \n\npy2-v1/\nos_architecture\n, \npy3-v1/\nos_architecture\n, etc. The initial \nindicates the python version (py2 vs py3) and then the version of the other \ndependencies, where \nv1\n is the minimal version required to run the SPT code\nand ever increasing versions are newer versions of the dependencies. At the\nmoment, \nv4\n is the bleeding edge`. For each combination of python and \ndependency set version there will be a version delineated by OS version and \nCPU architecture.\n\n\nDependency List\n\n\ngcc\nbinutils\npython\npython-setuptools\npython-pip\nboost\nhdf5\nnetcdf\nfftw\ngsl\ngnuplot\npgplot\ntcl\nbzip\nzlib\nxz\ncmake\nflac\nfreetype\ncfitsio\nopenblas\nglobus-toolkit\nnumpy\nscipy \nipython\njupyter\npyfits\nastropy\nnumexpr\nCython\nmatplotlib\nSphinx\ntables\nurwid\npyFFTW\nhealpy\nspectrum\ntornado\nSQLAlchemy\nPyYAML\nephem\nidlsave\nipdb\njsonschema\nh5py\npandas\nline_profiler\nmemory_profiler\nsimplejson\njoblib\nlmfit", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/spt/cvmfs/#cvmfs", 
            "text": "The SPT repo is handled by the experiment. The point of contact is Nathan\nWhitehorn. The structure follows a fairly simple pattern:  py2-v1/ os_architecture ,  py3-v1/ os_architecture , etc. The initial \nindicates the python version (py2 vs py3) and then the version of the other \ndependencies, where  v1  is the minimal version required to run the SPT code\nand ever increasing versions are newer versions of the dependencies. At the\nmoment,  v4  is the bleeding edge`. For each combination of python and \ndependency set version there will be a version delineated by OS version and \nCPU architecture.", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/spt/cvmfs/#dependency-list", 
            "text": "gcc\nbinutils\npython\npython-setuptools\npython-pip\nboost\nhdf5\nnetcdf\nfftw\ngsl\ngnuplot\npgplot\ntcl\nbzip\nzlib\nxz\ncmake\nflac\nfreetype\ncfitsio\nopenblas\nglobus-toolkit\nnumpy\nscipy \nipython\njupyter\npyfits\nastropy\nnumexpr\nCython\nmatplotlib\nSphinx\ntables\nurwid\npyFFTW\nhealpy\nspectrum\ntornado\nSQLAlchemy\nPyYAML\nephem\nidlsave\nipdb\njsonschema\nh5py\npandas\nline_profiler\nmemory_profiler\nsimplejson\njoblib\nlmfit", 
            "title": "Dependency List"
        }, 
        {
            "location": "/midscale-engagements/veritas/general/", 
            "text": "", 
            "title": "General"
        }, 
        {
            "location": "/midscale-engagements/veritas/cvmfs/", 
            "text": "CVMFS\n\n\nThe VERITAS repository is handled by OSG personnel. It is currently static. The\norganization is the same as the SPT repos. One thing to note is the need for \nGCC 4.9.x because of the version of ROOT required. This may change in the future.\nfuture.\n\n\nDependency List\n\n\nShortened list\nROOT\nGEANT4\npython\nCORSIKA", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/veritas/cvmfs/#cvmfs", 
            "text": "The VERITAS repository is handled by OSG personnel. It is currently static. The\norganization is the same as the SPT repos. One thing to note is the need for \nGCC 4.9.x because of the version of ROOT required. This may change in the future.\nfuture.", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/veritas/cvmfs/#dependency-list", 
            "text": "Shortened list\nROOT\nGEANT4\npython\nCORSIKA", 
            "title": "Dependency List"
        }, 
        {
            "location": "/midscale-engagements/xenon/general/", 
            "text": "XENON\n\n\nRequirements\n\n\nResources\n\n\nRucio", 
            "title": "General"
        }, 
        {
            "location": "/midscale-engagements/xenon/general/#xenon", 
            "text": "", 
            "title": "XENON"
        }, 
        {
            "location": "/midscale-engagements/xenon/general/#requirements", 
            "text": "", 
            "title": "Requirements"
        }, 
        {
            "location": "/midscale-engagements/xenon/general/#resources", 
            "text": "", 
            "title": "Resources"
        }, 
        {
            "location": "/midscale-engagements/xenon/general/#rucio", 
            "text": "", 
            "title": "Rucio"
        }, 
        {
            "location": "/midscale-engagements/xenon/cvmfs/", 
            "text": "CVMFS\n\n\nThe SPT repo is handled by the experiment. The repo is automatically updated \nwhenever there is a an update to the XENON1T GitHub repository using DeployHQ. \nThe software itself is being deployed through anaconda.\n\n\nDependency List\n\n\nShortened list\nROOT\nGEANT4\npython3", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/xenon/cvmfs/#cvmfs", 
            "text": "The SPT repo is handled by the experiment. The repo is automatically updated \nwhenever there is a an update to the XENON1T GitHub repository using DeployHQ. \nThe software itself is being deployed through anaconda.", 
            "title": "CVMFS"
        }, 
        {
            "location": "/midscale-engagements/xenon/cvmfs/#dependency-list", 
            "text": "Shortened list\nROOT\nGEANT4\npython3", 
            "title": "Dependency List"
        }
    ]
}